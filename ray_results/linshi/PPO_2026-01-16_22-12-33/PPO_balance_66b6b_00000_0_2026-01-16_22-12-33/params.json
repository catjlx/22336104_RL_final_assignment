{
  "callbacks": "<function train.<locals>.<lambda> at 0x796fd8365b40>",
  "clip_param": 0.2,
  "entropy_coeff": 0.0,
  "env": "balance",
  "env_config": {
    "continuous_actions": true,
    "device": "cpu",
    "max_steps": 200,
    "num_envs": 96,
    "reward_alpha": 0.8,
    "scenario_config": {
      "n_agents": 3
    },
    "scenario_name": "balance"
  },
  "evaluation_config": {
    "callbacks": "<function train.<locals>.<lambda> at 0x796fd8365bd0>",
    "env_config": {
      "num_envs": 1
    },
    "num_envs_per_worker": 1
  },
  "evaluation_interval": 5,
  "evaluation_num_workers": 1,
  "evaluation_parallel_to_training": true,
  "framework": "torch",
  "gamma": 0.99,
  "kl_coeff": 0.01,
  "kl_target": 0.01,
  "lambda": 0.9,
  "lr": 5e-05,
  "num_envs_per_worker": 96,
  "num_gpus": 0,
  "num_gpus_per_worker": 0,
  "num_sgd_iter": 40,
  "num_workers": 5,
  "rollout_fragment_length": 125,
  "sgd_minibatch_size": 4096,
  "train_batch_size": 60000,
  "vf_clip_param": Infinity,
  "vf_loss_coeff": 1.0
}